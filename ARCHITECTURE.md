# æ–°åª’ä½“æ™ºèƒ½è¿è¥å¹³å° - ç³»ç»Ÿæ¶æ„è®¾è®¡æ–‡æ¡£

**ç‰ˆæœ¬**: v2.2  
**æ›´æ–°æ—¥æœŸ**: 2026-02-14  
**çŠ¶æ€**: å·²ä¸Šçº¿è¿è¡Œ

---

## 1. æ¶æ„æ¦‚è§ˆ

### 1.1 æ•´ä½“æ¶æ„å›¾ (Mermaid)

```mermaid
graph TB
    subgraph User["ğŸ‘¤ ç”¨æˆ·å±‚"]
        U1["ğŸŒ Webæµè§ˆå™¨"]
        U2["ğŸ“± é£ä¹¦å®¢æˆ·ç«¯"]
    end

    subgraph Frontend["ğŸ–¥ï¸ å‰ç«¯å±‚ Vue3"]
        F1["ğŸ“Š Dashboard"]
        F2["ğŸ”¥ çƒ­ç‚¹å‘ç°"]
        F3["ğŸ“‹ å†…å®¹ç®¡ç†"]
        F4["â° å®šæ—¶ä»»åŠ¡"]
        F5["ğŸ“œ ç³»ç»Ÿæ—¥å¿—"]
    end

    subgraph Gateway["ğŸšª ç½‘å…³å±‚ Nginx"]
        G1["åå‘ä»£ç†"]
        G2["é™æ€èµ„æº"]
        G3["è´Ÿè½½å‡è¡¡"]
    end

    subgraph Backend["âš™ï¸ åç«¯å±‚ FastAPI"]
        API["REST API /api/v1"]
        WS["WebSocket /ws"]
        
        subgraph Core["æ ¸å¿ƒä¸šåŠ¡"]
            C1["å†…å®¹ç®¡ç† API"]
            C2["çƒ­ç‚¹ç®¡ç† API"]
            C3["å®šæ—¶ä»»åŠ¡ API"]
            C4["Agent API"]
        end
    end

    subgraph Agents["ğŸ¤– AI Agent å±‚ LangGraph"]
        A1["Orchestrator<br/>å·¥ä½œæµæ€»è°ƒåº¦"]
        A2["Hotspot Agent<br/>çƒ­ç‚¹è·å–"]
        A3["Research Agent<br/>çƒ­ç‚¹è°ƒç ”"]
        A4["Creator Agent<br/>å†…å®¹åˆ›ä½œ"]
        A5["Compliance Agent<br/>åˆè§„æ£€æŸ¥"]
    end

    subgraph Services["ğŸ”§ æœåŠ¡å±‚"]
        S1["Search Service<br/>Brave Search API"]
        S2["LLM Service<br/>è±†åŒ…å¤§æ¨¡å‹"]
        S3["Image Service<br/>å³æ¢¦å›¾ç‰‡ç”Ÿæˆ"]
        S4["Feishu Service<br/>é£ä¹¦é€šçŸ¥"]
        S5["MCP Service<br/>å°çº¢ä¹¦API"]
    end

    subgraph Tasks["â° å®šæ—¶ä»»åŠ¡ Celery"]
        T1["çƒ­ç‚¹è¿½è¸ª<br/>æ¯2å°æ—¶"]
        T2["è´¦å·åˆ·æ–°<br/>æ¯å°æ—¶"]
        T3["æ•°æ®æŠ“å–<br/>æ¯å°æ—¶"]
        T4["æ¯æ—¥æ¨é€<br/>22:00"]
        T5["æ¸…ç†ä»»åŠ¡<br/>03:00"]
    end

    subgraph Data["ğŸ’¾ æ•°æ®å±‚"]
        D1[(PostgreSQL<br/>ä¸»æ•°æ®åº“)]
        D2[(Redis<br/>ç¼“å­˜/é˜Ÿåˆ—)]
        D3[(RabbitMQ<br/>æ¶ˆæ¯é˜Ÿåˆ—)]
    end

    subgraph External["ğŸ”— å¤–éƒ¨æœåŠ¡"]
        E1["Brave Search"]
        E2["ç«å±±æ–¹èˆŸ LLM"]
        E3["å³æ¢¦ å›¾ç‰‡"]
        E4["é£ä¹¦ API"]
        E5["å°çº¢ä¹¦ MCP"]
    end

    U1 --> F1
    U2 --> E4
    
    F1 --> Gateway
    F2 --> Gateway
    F3 --> Gateway
    F4 --> Gateway
    F5 --> Gateway
    
    Gateway --> API
    Gateway --> WS
    
    API --> Core
    Core --> Agents
    Core --> Services
    
    Agents --> Services
    
    Tasks --> Agents
    Tasks --> Services
    
    Services --> External
    
    Backend --> Data
    Tasks --> Data
```

```

### 1.2 æŠ€æœ¯æ ˆæ€»è§ˆ

| å±‚çº§ | æŠ€æœ¯é€‰å‹ | ç‰ˆæœ¬ | ç”¨é€” |
|------|----------|------|------|
| **å‰ç«¯** | Vue 3 | 3.5+ | UIæ¡†æ¶ |
| | TypeScript | 5.0+ | ç±»å‹å®‰å…¨ |
| | Tailwind CSS | 3.4+ | åŸå­åŒ–CSS |
| | Vite | 5.0+ | æ„å»ºå·¥å…· |
| | Element Plus | 2.0+ | UIç»„ä»¶åº“ |
| | ECharts | 5.0+ | æ•°æ®å¯è§†åŒ– |
| **åç«¯** | FastAPI | 0.104+ | Webæ¡†æ¶ |
| | LangGraph | 0.0.40+ | Agentå·¥ä½œæµç¼–æ’ |
| | SQLAlchemy | 2.0+ | ORM |
| | Pydantic | 2.5+ | æ•°æ®éªŒè¯ |
| | Celery | 5.3+ | å®šæ—¶ä»»åŠ¡ |
| **AI/ML** | æ–¹èˆŸå¤§æ¨¡å‹ (å­—èŠ‚) | - | æ–‡æœ¬ç”Ÿæˆ |
| | å³æ¢¦ (Seedream) | - | é…å›¾ç”Ÿæˆ |
| | Brave Search API | - | å®æ—¶çƒ­ç‚¹æœç´¢ |
| **æ•°æ®** | PostgreSQL | 15 | ä¸»æ•°æ®å­˜å‚¨ |
| | Redis | 7 | ç¼“å­˜ã€ç»“æœåç«¯ |
| | RabbitMQ | - | æ¶ˆæ¯é˜Ÿåˆ— |
| **éƒ¨ç½²** | Docker | - | å®¹å™¨åŒ– |
| | Docker Compose | - | å¤šæœåŠ¡ç¼–æ’ |
| | Nginx | alpine | åå‘ä»£ç† |

---

## 2. Agentä½“ç³»è¯¦è§£

### 2.1 AgentèŒè´£çŸ©é˜µ

| Agent | è¾“å…¥ | è¾“å‡º | è°ƒç”¨æœåŠ¡ | æ ¸å¿ƒèƒ½åŠ› |
|-------|------|------|----------|----------|
| **Research Agent** | ç”¨æˆ·æŒ‡ä»¤/å®šæ—¶è§¦å‘ | çƒ­ç‚¹åˆ—è¡¨ | Brave Search API | å®æ—¶æœç´¢ã€å¤šæºèšåˆã€æ™ºèƒ½åˆ†ç±» |
| **Compliance Agent** | çƒ­ç‚¹æ ‡é¢˜/å†…å®¹æ­£æ–‡ | åˆè§„æŠ¥å‘Š | å…³é”®è¯è¿‡æ»¤+LLM | æ•æ„Ÿè¯æ£€æµ‹ã€é£é™©è¯„çº§ã€ä¿®æ”¹å»ºè®® |
| **Creator Agent** | åˆè§„çƒ­ç‚¹ | å®Œæ•´å†…å®¹ | æ–¹èˆŸå¤§æ¨¡å‹+å³æ¢¦ | æ–‡æ¡ˆç”Ÿæˆã€é…å›¾åˆ›ä½œã€æ ‡ç­¾æ¨è |
| **Publisher Agent** | å®¡æ ¸é€šè¿‡å†…å®¹ | å‘å¸ƒåŒ… | MCPæœåŠ¡ | æ ¼å¼æ•´ç†ã€ä¸€é”®å¤åˆ¶ã€çŠ¶æ€æ›´æ–° |

### 2.2 LangGraph å·¥ä½œæµå®šä¹‰ (Mermaid)

```mermaid
stateDiagram-v2
    [*] --> Research: å¯åŠ¨å·¥ä½œæµ
    
    Research --> ComplianceCheck: è·å–çƒ­ç‚¹
    
    ComplianceCheck --> Create: PASS
    ComplianceCheck --> Research: WARNING
    
    Create --> ContentReview: ç”Ÿæˆå†…å®¹
    
    ContentReview --> HumanReview: PASS
    ContentReview --> Create: NEED_FIX
    
    HumanReview --> Publish: APPROVED
    HumanReview --> Create: REJECTED
    
    Publish --> Analytics: å‘å¸ƒæˆåŠŸ
    Publish --> [*]: å¤±è´¥
    
    Analytics --> [*]: å®Œæˆ
    
    note right of Research
        Research Agent
        - Brave Searchæœç´¢çƒ­ç‚¹
        - çƒ­åº¦/ä¸“ä¸šåº¦/å®‰å…¨åº¦è¯„åˆ†
    end note
    
    note right of Create
        Creator Agent
        - LLMç”Ÿæˆæ ‡é¢˜(3ä¸ª)
        - ç”Ÿæˆæ­£æ–‡å†…å®¹
        - ç”Ÿæˆé…å›¾æç¤ºè¯
    end note
    
    note right of HumanReview
        äººå·¥å®¡æ ¸èŠ‚ç‚¹
        - é£ä¹¦é€šçŸ¥ç”¨æˆ·
        - ç­‰å¾…ç”¨æˆ·å†³ç­–
        - é€šè¿‡/æ‹’ç»/ä¿®æ”¹
    end note
```

### 2.3 ä»£ç å®ç°

```python
# app/agents/orchestrator.py

from langgraph.graph import StateGraph, END

workflow = StateGraph(WorkflowState)

# èŠ‚ç‚¹å®šä¹‰
workflow.add_node("research", research_node)           # çƒ­ç‚¹å‘ç°
workflow.add_node("compliance_check", compliance_check_node)  # çƒ­ç‚¹åˆè§„
workflow.add_node("create", create_node)              # å†…å®¹åˆ›ä½œ
workflow.add_node("compliance_review", compliance_review_node) # å†…å®¹åˆè§„
workflow.add_node("review", human_review_node)        # äººå·¥å®¡æ ¸
workflow.add_node("publish", publish_node)            # å‘å¸ƒç®¡ç†
workflow.add_node("analytics", analytics_node)        # æ•°æ®åˆ†æ

# è¾¹å®šä¹‰ï¼ˆæµè½¬é€»è¾‘ï¼‰
workflow.set_entry_point("research")
workflow.add_edge("research", "compliance_check")
workflow.add_conditional_edges(
    "compliance_check",
    route_compliance_check,
    {"create": "create", "end": END}
)
workflow.add_edge("create", "compliance_review")
workflow.add_conditional_edges(
    "compliance_review",
    route_compliance_review,
    {"review": "review", "end": END}
)
workflow.add_conditional_edges(
    "review",
    route_review_decision,
    {"publish": "publish", "create": "create", "end": END}
)
workflow.add_edge("publish", "analytics")
workflow.add_edge("analytics", END)
```

---

## 3. æ ¸å¿ƒæœåŠ¡è¯¦è§£

### 3.1 Search Service (çƒ­ç‚¹æœç´¢)

```python
# app/services/search.py

class HotspotSearchService:
    """å®æ—¶çƒ­ç‚¹æœç´¢æœåŠ¡"""
    
    async def search_brave(self, query: str, count: int = 10) -> List[Dict]:
        """ä½¿ç”¨ Brave Search API æœç´¢"""
        # API: https://api.search.brave.com/res/v1/news/search
        
    async def search_finance_news(self) -> List[Dict]:
        """æœç´¢è´¢ç»æ–°é—»çƒ­ç‚¹"""
        # å…³é”®è¯æ± : å¤®è¡Œã€LPRã€é»„é‡‘ã€å…»è€é‡‘ã€æ•°å­—äººæ°‘å¸ç­‰
        
    def categorize_topic(self, title: str, summary: str) -> str:
        """çƒ­ç‚¹åˆ†ç±»"""
        # åˆ†ç±»: è´§å¸æ”¿ç­–ã€åˆ©ç‡ã€è‚¡å¸‚ã€åŸºé‡‘ã€æˆ¿äº§ã€æ•°å­—è´§å¸ç­‰
```

**APIé…ç½®**:
```bash
BRAVE_API_KEY=${BRAVE_API_KEY}  # ä» https://brave.com/search/api/ è·å–
```

### 3.2 LLM Service (å†…å®¹ç”Ÿæˆ)

```python
# app/services/llm.py

class LLMService:
    """å¤§æ¨¡å‹æœåŠ¡ - æ–¹èˆŸå¤§æ¨¡å‹"""
    
    PERSONA_PROMPT = """ä½ æ˜¯ä¸€ä½å°çº¢ä¹¦é“¶è¡Œåšä¸»"é“¶è¡Œå°å§å§"..."""
    
    async def generate_content(self, topic: dict) -> dict:
        """ç”Ÿæˆå°çº¢ä¹¦å†…å®¹"""
        # è¾“å…¥: {title, summary, category}
        # è¾“å‡º: {titles[], body, tags[], image_prompts[]}
```

### 3.3 Image Service (é…å›¾ç”Ÿæˆ)

```python
# app/services/image.py

class ImageGenerationService:
    """å›¾åƒç”ŸæˆæœåŠ¡ - å³æ¢¦æ¨¡å‹"""
    
    async def generate_images(
        self, 
        prompts: List[str], 
        content_id: str,
        width: int = 1024,
        height: int = 1536  # å°çº¢ä¹¦å°ºå¯¸
    ) -> List[dict]:
        """ç”Ÿæˆé…å›¾"""
```

### 3.4 MCP Service (å°çº¢ä¹¦API)

```python
# app/services/xhs_mcp.py

class XHSMCPService:
    """å°çº¢ä¹¦ MCP æœåŠ¡"""
    
    async def get_user_profile(self) -> dict:
        """è·å–ç”¨æˆ·è´¦å·æ•°æ®"""
        
    async def get_notes(self, limit: int = 20) -> list:
        """è·å–ç¬”è®°åˆ—è¡¨"""
        
    async def publish_note(self, title: str, content: str, images: list) -> dict:
        """å‘å¸ƒç¬”è®°"""
```

### 3.5 Feishu Service (é£ä¹¦é€šçŸ¥)

```python
# app/services/feishu.py

async def send_review_notification(
    content_id: str,
    title: str,
    preview: str,
    created_at: str
) -> bool:
    """å‘é€å®¡æ ¸é€šçŸ¥åˆ°é£ä¹¦"""
```

---

## 4. å®šæ—¶ä»»åŠ¡æ¶æ„

### 4.1 Celery é…ç½®

```python
# app/tasks/celery_app.py

celery_app.conf.beat_schedule = {
    # æŠ“å–å·²å‘å¸ƒå†…å®¹çš„æ•°æ®
    "fetch-published-analytics": {
        "task": "tasks.fetch_analytics",
        "schedule": 3600.0,  # æ¯å°æ—¶
    },
    # çƒ­ç‚¹è¿½è¸ª - æ¯2å°æ—¶æŠ“å–ï¼ˆ7:00-23:00ï¼‰
    "fetch-hotspots": {
        "task": "tasks.fetch_hotspots",
        "schedule": 7200.0,  # 2å°æ—¶
    },
    # æ¯æ—¥çƒ­ç‚¹ç²¾é€‰æ¨é€
    "send-daily-hotspot-digest": {
        "task": "tasks.send_daily_hotspot_digest",
        "schedule": crontab(hour=22, minute=0),  # æ¯æ™š22:00
    },
    # æ¸…ç†è¿‡æœŸçƒ­ç‚¹
    "clean-expired-hotspots": {
        "task": "tasks.clean_expired_hotspots",
        "schedule": crontab(hour=3, minute=0),  # æ¯å¤©å‡Œæ™¨3:00
    },
    # åˆ·æ–°å°çº¢ä¹¦è´¦å·æ•°æ® - æ¯å°æ—¶
    "refresh-xhs-account": {
        "task": "tasks.refresh_xhs_account",
        "schedule": 3600.0,  # æ¯å°æ—¶
    },
    # Agent çƒ­ç‚¹æŠ“å– V2 - æ¯2å°æ—¶
    "fetch-hotspots-v2": {
        "task": "tasks.fetch_hotspots_v2",
        "schedule": 7200.0,  # 2å°æ—¶
    },
}
```

### 4.2 å®šæ—¶ä»»åŠ¡åˆ—è¡¨

| ä»»åŠ¡åç§° | è°ƒåº¦è§„åˆ™ | ä¼˜å…ˆçº§ | åŠŸèƒ½æè¿° |
|---------|---------|-------|---------|
| fetch_hotspots | æ¯2å°æ—¶ (7-23ç‚¹) | é«˜ | æŠ“å–å…¨ç½‘çƒ­ç‚¹è¯é¢˜ |
| fetch_hotspots_v2 | æ¯2å°æ—¶ | ä¸­ | Agentæ¨¡å¼çƒ­ç‚¹æŠ“å– |
| refresh_xhs_account | æ¯å°æ—¶ | ä¸­ | åˆ·æ–°å°çº¢ä¹¦è´¦å·æ•°æ® |
| fetch_analytics | æ¯å°æ—¶ | ä¸­ | æŠ“å–å·²å‘å¸ƒå†…å®¹æ•°æ® |
| send_daily_hotspot_digest | æ¯å¤©22:00 | ä¸­ | æ¯æ—¥çƒ­ç‚¹ç²¾é€‰æ¨é€ |
| clean_expired_hotspots | æ¯å¤©03:00 | ä½ | æ¸…ç†è¿‡æœŸçƒ­ç‚¹æ•°æ® |

---

## 5. æ•°æ®æ¨¡å‹

### 5.1 ERå›¾ (Mermaid)

```mermaid
erDiagram
    HotTopic ||--o{ Content : "å…³è”"
    HotTopic ||--o{ HotTopicTrend : "è¶‹åŠ¿è®°å½•"
    HotTopic ||--o{ HotTopicAlert : "æ¨é€è®°å½•"
    Content ||--o{ ContentMetric : "æŒ‡æ ‡æ•°æ®"
    Content ||--o{ WorkflowLog : "æ‰§è¡Œæ—¥å¿—"
    
    HotTopic {
        string id PK
        string title "æ ‡é¢˜"
        string summary "æ‘˜è¦"
        int heat_score "çƒ­åº¦åˆ†"
        int professional_score "ä¸“ä¸šåˆ†"
        int safety_score "å®‰å…¨åˆ†"
        int total_score "ç»¼åˆåˆ†"
        string trend "è¶‹åŠ¿ rising/falling"
        string category "åˆ†ç±»"
        json keywords "å…³é”®è¯"
        string status "çŠ¶æ€"
        string compliance_flag "åˆè§„æ ‡è®°"
        datetime discovered_at "å‘ç°æ—¶é—´"
        datetime expires_at "è¿‡æœŸæ—¶é—´"
    }
    
    Content {
        string id PK
        string workflow_id UK "å·¥ä½œæµID"
        string topic_id FK "çƒ­ç‚¹ID"
        json titles "å€™é€‰æ ‡é¢˜(3ä¸ª)"
        text body "æ­£æ–‡"
        json tags "æ ‡ç­¾"
        json image_prompts "é…å›¾æç¤ºè¯"
        json images "ç”Ÿæˆçš„å›¾ç‰‡"
        string status "çŠ¶æ€ CREATING/REVIEWING/APPROVED"
        int revision_round "ä¿®æ”¹è½®æ¬¡"
        datetime approved_at "é€šè¿‡æ—¶é—´"
        datetime published_at "å‘å¸ƒæ—¶é—´"
    }
    
    ContentMetric {
        string id PK
        string content_id FK
        int views "é˜…è¯»é‡"
        int likes "ç‚¹èµ"
        int comments "è¯„è®º"
        int favorites "æ”¶è—"
        float engagement_rate "äº’åŠ¨ç‡"
    }
    
    HotTopicTrend {
        string id PK
        string topic_id FK
        int heat_score "çƒ­åº¦åˆ†"
        int search_index "æœç´¢æŒ‡æ•°"
        int discuss_count "è®¨è®ºé‡"
        datetime recorded_at "è®°å½•æ—¶é—´"
    }
    
    WorkflowLog {
        string id PK
        string workflow_id "å·¥ä½œæµID"
        string agent_name "Agentåç§°"
        string action "åŠ¨ä½œ"
        json input_data "è¾“å…¥"
        json output_data "è¾“å‡º"
        string status "çŠ¶æ€"
        int duration_ms "è€—æ—¶"
    }
```

### 5.2 æ ¸å¿ƒå®ä½“è¯´æ˜

```python
# app/models/v4_models.py

class HotTopic(Base):
    """çƒ­ç‚¹è¡¨ - PRD v4.0"""
    # è¯„åˆ†ç»´åº¦: heat_score, professional_score, safety_score, innovation_score, total_score
    # è¿½è¸ªå­—æ®µ: trend, category, keywords, search_index, discuss_count, read_count
    # çŠ¶æ€ç®¡ç†: compliance_flag, status, is_notified

class Content(Base):
    """å†…å®¹è¡¨"""
    # åˆ›ä½œæ•°æ®: titles(3ä¸ªå€™é€‰), body, tags, image_prompts, images
    # å®¡æ ¸çŠ¶æ€: CREATING â†’ REVIEWING â†’ APPROVED â†’ PUBLISHED
    # ä¿®æ”¹è®°å½•: revision_round, revision_notes, error_message

class ContentMetric(Base):
    """å†…å®¹è¡¨ç°æŒ‡æ ‡è¡¨"""
    # äº’åŠ¨æ•°æ®: views, likes, comments, favorites, shares
    # è®¡ç®—æŒ‡æ ‡: engagement_rate
    # æ•°æ®æ¥æº: data_source (manual/api/demo)
```

---

## 6. API è®¾è®¡

### 6.1 RESTful API åˆ—è¡¨

```
# å†…å®¹ç®¡ç†
GET    /api/v1/contents                    # è·å–å†…å®¹åˆ—è¡¨
GET    /api/v1/contents/{id}               # è·å–å†…å®¹è¯¦æƒ…
POST   /api/v1/contents/{id}/approve       # å®¡æ ¸é€šè¿‡
POST   /api/v1/contents/{id}/reject        # æ‹’ç»å†…å®¹
POST   /api/v1/contents/{id}/auto-publish  # å‘å¸ƒå†…å®¹
POST   /api/v1/contents/{id}/regenerate    # é‡æ–°ç”Ÿæˆ

# çƒ­ç‚¹ç®¡ç†
GET    /api/v1/agent/hotspots/search       # å®æ—¶æœç´¢çƒ­ç‚¹
GET    /api/v1/hotspots                    # è·å–çƒ­ç‚¹åˆ—è¡¨
GET    /api/v1/hotspots/{id}               # è·å–çƒ­ç‚¹è¯¦æƒ…

# Workflow
POST   /api/v1/agent/workflow/start        # å¯åŠ¨åˆ›ä½œå·¥ä½œæµ
POST   /api/v1/agent/workflow/batch        # æ‰¹é‡åˆ›ä½œ
GET    /api/v1/agent/workflow/{id}         # æŸ¥è¯¢å·¥ä½œæµçŠ¶æ€

# å®šæ—¶ä»»åŠ¡
GET    /api/v1/scheduler/tasks             # è·å–å®šæ—¶ä»»åŠ¡åˆ—è¡¨
GET    /api/v1/scheduler/status            # è·å–è°ƒåº¦å™¨çŠ¶æ€
GET    /api/v1/scheduler/executions        # è·å–æ‰§è¡Œå†å²
POST   /api/v1/scheduler/tasks/{id}/run    # ç«‹å³æ‰§è¡Œä»»åŠ¡

# æ–‡æ¡£
GET    /api/docs                           # Swagger UI
GET    /api/redoc                         # ReDoc
```

### 6.2 WebSocket API

```
WS /ws/{client_id}

# æ¶ˆæ¯ç±»å‹
ping/pong          # å¿ƒè·³æ£€æµ‹
review_decision    # å®¡æ ¸å†³ç­–
workflow_update    # å·¥ä½œæµçŠ¶æ€æ›´æ–°
notification       # ç³»ç»Ÿé€šçŸ¥
```

---

## 7. éƒ¨ç½²æ¶æ„

### 7.1 Docker Compose é…ç½®

```yaml
# docker-compose.yml

services:
  # Nginx ç½‘å…³
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./frontend/dist:/usr/share/nginx/html:ro
    depends_on:
      - api

  # API æœåŠ¡
  api:
    build: ./backend
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/xhs_platform
      - REDIS_URL=redis://redis:6379/0
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
      - ARK_API_KEY=${ARK_API_KEY}
      - ARK_MODEL_ENDPOINT=${ARK_MODEL_ENDPOINT}
      - ARK_IMAGE_ENDPOINT=${ARK_IMAGE_ENDPOINT}
      - BRAVE_API_KEY=${BRAVE_API_KEY}
      - MCP_URL=http://xiaohongshu-mcp:18060/mcp
    depends_on:
      - postgres
      - redis
      - rabbitmq

  # Celery Worker
  celery-worker:
    build: ./backend
    command: celery -A app.tasks.celery_app worker --loglevel=info
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/xhs_platform
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672/
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - postgres
      - redis
      - rabbitmq

  # Celery Beat
  celery-beat:
    build: ./backend
    command: celery -A app.tasks.celery_app beat --loglevel=info
    environment:
      - CELERY_BROKER_URL=amqp://guest:guest@rabbitmq:5672/
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - redis
      - rabbitmq

  # PostgreSQL
  postgres:
    image: postgres:15-alpine
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=xhs_platform

  # Redis
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data

  # RabbitMQ
  rabbitmq:
    image: rabbitmq:3-alpine
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq

  # å°çº¢ä¹¦ MCP æœåŠ¡
  xiaohongshu-mcp:
    build: ./mcp
    ports:
      - "18060:18060"
    volumes:
      - ./mcp/cookies.json:/app/cookies.json:ro

volumes:
  postgres_data:
  redis_data:
  rabbitmq_data:
```

### 7.2 Nginx é…ç½®

```nginx
server {
    listen 80;
    
    # å‰ç«¯é™æ€èµ„æº
    location / {
        root /usr/share/nginx/html;
        index index.html;
        try_files $uri $uri/ /index.html;
    }
    
    # API ä»£ç†åˆ°åç«¯
    location /api/ {
        proxy_pass http://api:8000/api/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
    
    # WebSocket ä»£ç†
    location /ws/ {
        proxy_pass http://api:8000/ws/;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

---

## 8. ç¯å¢ƒå˜é‡é…ç½®

```bash
# === åº”ç”¨é…ç½® ===
APP_NAME=æ–°åª’ä½“æ™ºèƒ½è¿è¥å¹³å°
DEBUG=True
API_KEY=xhs_agent_internal_key
FRONTEND_URL=http://localhost

# === æ•°æ®åº“é…ç½® ===
DATABASE_URL=postgresql://postgres:postgres@postgres:5432/xhs_platform
REDIS_URL=redis://localhost:6379/0
RABBITMQ_URL=amqp://guest:guest@localhost:5672/

# === æ–¹èˆŸå¤§æ¨¡å‹ (æ–‡æœ¬ç”Ÿæˆ) ===
ARK_API_KEY=${ARK_API_KEY}
ARK_MODEL_ENDPOINT=${ARK_MODEL_ENDPOINT}
ARK_IMAGE_ENDPOINT=${ARK_IMAGE_ENDPOINT}
ARK_BASE_URL=https://ark.cn-beijing.volces.com/api/v3

# === Brave Search (çƒ­ç‚¹æœç´¢) ===
BRAVE_API_KEY=${BRAVE_API_KEY}

# === MCP æœåŠ¡é…ç½® ===
MCP_URL=http://localhost:18060/mcp
MCP_ENABLED=true

# === å°çº¢ä¹¦è´¦å·é…ç½® ===
XHS_USER_ID=${XHS_USER_ID}
```

---

## 9. å…³é”®ä¸šåŠ¡æµç¨‹

### 9.1 å•æ¬¡åˆ›ä½œæµç¨‹ (Mermaid)

```mermaid
sequenceDiagram
    autonumber
    
    participant User as ç”¨æˆ·
    participant API as APIæœåŠ¡
    participant DB as æ•°æ®åº“
    participant Agent as LangGraph
    participant LLM as æ–¹èˆŸå¤§æ¨¡å‹
    participant Feishu as é£ä¹¦
    
    User->>API: POST /workflow/start
    API->>DB: åˆ›å»ºContentè®°å½•<br/>(status=CREATING)
    API->>User: è¿”å›workflow_id
    
    par å¼‚æ­¥æ‰§è¡Œå·¥ä½œæµ
        API->>Agent: å¯åŠ¨LangGraphå·¥ä½œæµ
        
        Agent->>Agent: Research Agent<br/>Brave Searchæœç´¢çƒ­ç‚¹
        Agent->>Agent: Compliance Agent<br/>åˆè§„æ£€æŸ¥
        Agent->>LLM: Creator Agent<br/>ç”Ÿæˆæ–‡æ¡ˆ
        LLM-->>Agent: è¿”å›titles/body/tags
        Agent->>LLM: Image Service<br/>ç”Ÿæˆé…å›¾
        
        Agent->>Feishu: å‘é€å®¡æ ¸é€šçŸ¥
        Agent->>DB: æ›´æ–°Content<br/>(status=REVIEWING)
    end
    
    User->>Feishu: å›å¤"é€šè¿‡"
    Feishu->>API: å®¡æ ¸å›è°ƒ
    API->>DB: æ›´æ–°Content<br/>(status=APPROVED)
    API->>Feishu: å›å¤å®¡æ ¸ç»“æœ
```

### 9.2 å®šæ—¶ä»»åŠ¡æ‰§è¡Œæµç¨‹

```mermaid
sequenceDiagram
    autonumber
    
    participant Beat as Celery Beat
    participant Queue as RabbitMQé˜Ÿåˆ—
    participant Worker as Celery Worker
    participant Agent as Hotspot Agent
    participant Search as Brave Search
    participant DB as PostgreSQL
    participant Feishu as é£ä¹¦
    
    Beat->>Beat: åˆ°è¾¾è°ƒåº¦æ—¶é—´
    Beat->>Queue: å‘é€ä»»åŠ¡æ¶ˆæ¯
    
    Worker->>Queue: è·å–ä»»åŠ¡
    Worker->>Agent: æ‰§è¡Œfetch_hotspots
    
    Agent->>Search: æœç´¢è´¢ç»çƒ­ç‚¹
    Search-->>Agent: è¿”å›çƒ­ç‚¹åˆ—è¡¨
    
    Agent->>Agent: åˆ†ç±»/è¯„åˆ†/å»é‡
    Agent->>DB: ä¿å­˜HotTopicè®°å½•
    
    alt é«˜çƒ­åº¦çƒ­ç‚¹
        Agent->>Feishu: å‘é€å®æ—¶æ¨é€
    end
```

---

## 10. Dockeréƒ¨ç½²æ¶æ„

### 10.1 å®¹å™¨æ¶æ„å›¾ (Mermaid)

```mermaid
graph TB
    subgraph DockerCompose["ğŸ³ Docker Compose ç¯å¢ƒ"]
        subgraph Network["xhs-network (bridge)"]
            Nginx["ğŸŒ Nginx<br/>Port: 80<br/>Container: xhs_nginx"]
            
            subgraph BackendServices["åç«¯æœåŠ¡"]
                API["âš¡ FastAPI<br/>Port: 8000<br/>Container: xhs_api"]
                Worker["ğŸ”§ Celery Worker<br/>Container: xhs_worker"]
                Scheduler["â° Celery Beat<br/>Container: xhs_scheduler"]
            end
            
            subgraph DataServices["æ•°æ®æœåŠ¡"]
                Postgres["ğŸ˜ PostgreSQL<br/>Port: 5432<br/>Container: xhs_postgres"]
                Redis["ğŸ”´ Redis<br/>Port: 6379<br/>Container: xhs_redis"]
                RabbitMQ["ğŸ° RabbitMQ<br/>Port: 5672<br/>Container: xhs_rabbitmq"]
            end
        end
    end
    
    subgraph External["å¤–éƒ¨æœåŠ¡"]
        MCP["ğŸ”Œ MCP Server<br/>Host: host.docker.internal:18060"]
        Brave["ğŸ” Brave Search API"]
        ArkLLM["ğŸ¤– æ–¹èˆŸå¤§æ¨¡å‹"]
        Feishu["ğŸ’¬ é£ä¹¦ API"]
    end
    
    User["ğŸ‘¤ ç”¨æˆ·æµè§ˆå™¨"] -->|HTTP| Nginx
    Nginx -->|/api/*| API
    Nginx -->|é™æ€èµ„æº| Frontend["ğŸ“ å‰ç«¯æ–‡ä»¶"]
    
    API --> Postgres
    API --> Redis
    API --> RabbitMQ
    API -->|HTTP| MCP
    API -->|HTTPS| Brave
    API -->|HTTPS| ArkLLM
    API -->|HTTPS| Feishu
    
    Worker --> Postgres
    Worker --> Redis
    Worker --> RabbitMQ
    
    Scheduler --> RabbitMQ
    
    Worker -.->|å¼‚æ­¥ä»»åŠ¡| API
```

### 10.2 æœåŠ¡ä¾èµ–å…³ç³»

```mermaid
flowchart TD
    subgraph å¯åŠ¨é¡ºåº
        DB["1ï¸âƒ£ PostgreSQL<br/>Redis<br/>RabbitMQ"] --å¥åº·æ£€æŸ¥é€šè¿‡--> API
        API --> Worker
        API --> Scheduler
        API --> Nginx
    end
    
    style DB fill:#e8f5e9
    style API fill:#e3f2fd
    style Nginx fill:#fff3e0
```

| æœåŠ¡ | å®¹å™¨å | å†…éƒ¨ç«¯å£ | å¤–éƒ¨ç«¯å£ | ä¾èµ– |
|------|--------|---------|---------|------|
| **Nginx** | xhs_nginx | 80 | 80 | api |
| **API** | xhs_api | 8000 | - | postgres, redis, rabbitmq |
| **Worker** | xhs_worker | - | - | postgres, rabbitmq |
| **Scheduler** | xhs_scheduler | - | - | postgres, rabbitmq |
| **PostgreSQL** | xhs_postgres | 5432 | - | - |
| **Redis** | xhs_redis | 6379 | - | - |
| **RabbitMQ** | xhs_rabbitmq | 5672 | - | - |

---

## 11. éƒ¨ç½²è¯´æ˜

### 11.1 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### æ­¥éª¤1: ç¯å¢ƒå‡†å¤‡

```bash
# ç³»ç»Ÿè¦æ±‚
- Docker 20.10+
- Docker Compose 2.0+
- 4GB+ RAM
- 10GB+ ç£ç›˜ç©ºé—´

# å…‹éš†é¡¹ç›®
git clone https://github.com/Jenny-Huijing/openclaw-mop.git
cd xhs_platform
```

#### æ­¥éª¤2: é…ç½®ç¯å¢ƒå˜é‡

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ä»¥ä¸‹å¿…éœ€é…ç½®
nano .env
```

**å¿…éœ€é…ç½®é¡¹ï¼š**

```bash
# === æ–¹èˆŸå¤§æ¨¡å‹ (æ–‡æœ¬ç”Ÿæˆ) ===
ARK_API_KEY=your-ark-api-key
ARK_MODEL_ENDPOINT=ep-xxxxxxxxx    # è±†åŒ…æ–‡æœ¬æ¨¡å‹ç«¯ç‚¹
ARK_IMAGE_ENDPOINT=ep-xxxxxxxxx    # å³æ¢¦å›¾åƒæ¨¡å‹ç«¯ç‚¹

# === Brave Search (çƒ­ç‚¹æœç´¢) ===
BRAVE_API_KEY=your-brave-api-key

# === MCP æœåŠ¡é…ç½® ===
MCP_URL=http://host.docker.internal:18060/mcp
MCP_ENABLED=true

# === å°çº¢ä¹¦è´¦å· ===
XHS_USER_ID=your-xiaohongshu-user-id

# === å‰ç«¯åœ°å€ ===
FRONTEND_URL=http://localhost
```

#### æ­¥éª¤3: æ„å»ºå¹¶å¯åŠ¨æœåŠ¡

```bash
# æ„å»ºé•œåƒå¹¶å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d --build

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# ç­‰å¾…æ‰€æœ‰æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡ï¼ˆçº¦30ç§’ï¼‰
docker-compose ps | grep "healthy"
```

#### æ­¥éª¤4: éªŒè¯éƒ¨ç½²

```bash
# æµ‹è¯•API
curl http://localhost/api/v1/contents?limit=1

# æŸ¥çœ‹APIæ—¥å¿—
docker logs -f xhs_api

# æŸ¥çœ‹å®šæ—¶ä»»åŠ¡æ—¥å¿—
docker logs -f xhs_worker
docker logs -f xhs_scheduler
```

### 11.2 æ—¥å¸¸è¿ç»´å‘½ä»¤

```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker logs -f xhs_api              # APIæœåŠ¡æ—¥å¿—
docker logs -f xhs_worker           # Workeræ—¥å¿—
docker logs -f xhs_scheduler        # å®šæ—¶å™¨æ—¥å¿—
docker logs -f xhs_postgres         # æ•°æ®åº“æ—¥å¿—

# é‡å¯æœåŠ¡
docker-compose restart api          # é‡å¯API
docker-compose restart worker       # é‡å¯Worker
docker-compose restart              # é‡å¯æ‰€æœ‰æœåŠ¡

# åœæ­¢æœåŠ¡
docker-compose stop                 # åœæ­¢ï¼ˆä¿ç•™å®¹å™¨ï¼‰
docker-compose down                 # åœæ­¢å¹¶åˆ é™¤å®¹å™¨
docker-compose down -v              # åœæ­¢å¹¶åˆ é™¤å®¹å™¨+æ•°æ®å·ï¼ˆå±é™©ï¼ï¼‰

# è¿›å…¥å®¹å™¨è°ƒè¯•
docker exec -it xhs_api bash
docker exec -it xhs_postgres psql -U postgres -d xhs_platform

# æŸ¥çœ‹èµ„æºä½¿ç”¨
docker stats
```

### 11.3 æ•°æ®å¤‡ä»½ä¸æ¢å¤

```bash
# å¤‡ä»½æ•°æ®åº“
docker exec xhs_postgres pg_dump -U postgres xhs_platform > backup_$(date +%Y%m%d).sql

# æ¢å¤æ•°æ®åº“
docker exec -i xhs_postgres psql -U postgres -d xhs_platform < backup_20260214.sql

# å¤‡ä»½æ•°æ®å·
docker run --rm -v xhs_platform_postgres_data:/data -v $(pwd):/backup alpine tar czf /backup/postgres_backup.tar.gz -C /data .
```

### 11.4 æ›´æ–°éƒ¨ç½²

```bash
# æ‹‰å–æœ€æ–°ä»£ç 
git pull origin main

# é‡æ–°æ„å»ºå¹¶é‡å¯
docker-compose up -d --build

# ä»…æ›´æ–°ä»£ç ï¼ˆå¼€å‘æ¨¡å¼ï¼‰
docker-compose restart api worker scheduler
```

---

## 12. æœ¬åœ°å¼€å‘å¯åŠ¨

```bash
# 1. å¯åŠ¨åŸºç¡€è®¾æ–½
docker-compose up -d postgres redis rabbitmq

# 2. å®‰è£…åç«¯ä¾èµ–
cd backend
pip install -r requirements.txt

# 3. å¯åŠ¨APIæœåŠ¡
uvicorn app.main:app --reload --port 8000

# 4. å¯åŠ¨Celery Worker (æ–°ç»ˆç«¯)
celery -A app.tasks.celery_app worker --loglevel=info

# 5. å¯åŠ¨Celery Beat (æ–°ç»ˆç«¯)
celery -A app.tasks.celery_app beat --loglevel=info

# 6. å¯åŠ¨å‰ç«¯ (æ–°ç»ˆç«¯)
cd frontend
npm install
npm run dev
```

---

## 13. æ¶æ„æ¼”è¿›è®°å½•

| æ—¥æœŸ | ç‰ˆæœ¬ | å˜æ›´å†…å®¹ |
|------|------|----------|
| 2026-02-14 | v2.2 | ç»Ÿä¸€Dockeréƒ¨ç½²ï¼Œæ‰€æœ‰æœåŠ¡å®¹å™¨åŒ– |
| 2026-02-14 | v2.2 | æ›´æ–°Nginxé…ç½®ï¼Œæ”¯æŒDockerå†…éƒ¨ç½‘ç»œ |
| 2026-02-14 | v2.2 | æ·»åŠ è¯¦ç»†éƒ¨ç½²æ–‡æ¡£å’Œè¿ç»´å‘½ä»¤ |
| 2026-02-14 | v2.1 | æ·»åŠ Celeryå®šæ—¶ä»»åŠ¡ç³»ç»Ÿï¼Œä¿®å¤é…ç½®é—®é¢˜ |
| 2026-02-14 | v2.1 | æ·»åŠ MCPæœåŠ¡é›†æˆï¼Œæ”¯æŒå°çº¢ä¹¦è´¦å·æ•°æ®è·å– |
| 2026-02-14 | v2.1 | æ·»åŠ é£ä¹¦æœåŠ¡ï¼Œå®ç°å®¡æ ¸é€šçŸ¥æ¨é€ |
| 2026-02-14 | v2.1 | æ·»åŠ FRONTEND_URLé…ç½®å­—æ®µ |
| 2026-02-12 | v2.0 | å¼•å…¥ LangGraph å·¥ä½œæµç¼–æ’ï¼Œå®ç°å¤šAgentåä½œ |
| 2026-02-12 | v2.0 | æ¥å…¥ Brave Search API å®æ—¶çƒ­ç‚¹æœç´¢ |
| 2026-02-12 | v2.0 | æ¥å…¥æ–¹èˆŸå¤§æ¨¡å‹ (è±†åŒ…) å†…å®¹ç”Ÿæˆ |
| 2026-02-12 | v2.0 | æ¥å…¥å³æ¢¦æ¨¡å‹é…å›¾ç”Ÿæˆ |
| 2026-02-10 | v1.0 | åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºç¡€CRUDåŠŸèƒ½ |

---

## 13. é¡¹ç›®ç›®å½•ç»“æ„

```
xhs_platform/
â”œâ”€â”€ README.md                 # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ ARCHITECTURE.md          # æ¶æ„æ–‡æ¡£ (æœ¬æ–‡æ¡£)
â”œâ”€â”€ docker-compose.yml       # Dockerç¼–æ’
â”œâ”€â”€ .env.example            # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”‚
â”œâ”€â”€ backend/                # åç«¯æœåŠ¡
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/        # AI Agentå®ç°
â”‚   â”‚   â”‚   â”œâ”€â”€ orchestrator.py      # å·¥ä½œæµæ€»è°ƒåº¦
â”‚   â”‚   â”‚   â””â”€â”€ hotspot_agent.py     # çƒ­ç‚¹è·å–Agent
â”‚   â”‚   â”œâ”€â”€ api/           # APIè·¯ç”±
â”‚   â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚   â”‚       â”œâ”€â”€ agent.py         # Agent API
â”‚   â”‚   â”‚       â”œâ”€â”€ content.py       # å†…å®¹API
â”‚   â”‚   â”‚       â”œâ”€â”€ scheduler.py     # å®šæ—¶ä»»åŠ¡API
â”‚   â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ core/          # æ ¸å¿ƒé…ç½®
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py            # åº”ç”¨é…ç½®
â”‚   â”‚   â”‚   â””â”€â”€ database.py          # æ•°æ®åº“é…ç½®
â”‚   â”‚   â”œâ”€â”€ models/        # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”‚   â””â”€â”€ v4_models.py         # PRD v4.0æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ services/      # ä¸šåŠ¡æœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py              # LLMæœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ search.py           # æœç´¢æœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ image.py            # å›¾ç‰‡æœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ feishu.py           # é£ä¹¦æœåŠ¡
â”‚   â”‚   â”‚   â””â”€â”€ xhs_mcp.py          # MCPæœåŠ¡
â”‚   â”‚   â””â”€â”€ tasks/         # å®šæ—¶ä»»åŠ¡
â”‚   â”‚       â”œâ”€â”€ celery_app.py       # Celeryé…ç½®
â”‚   â”‚       â”œâ”€â”€ content_tasks.py    # å†…å®¹ä»»åŠ¡
â”‚   â”‚       â””â”€â”€ hotspot_tasks.py    # çƒ­ç‚¹ä»»åŠ¡
â”‚   â”œâ”€â”€ requirements.txt    # Pythonä¾èµ–
â”‚   â””â”€â”€ Dockerfile         # åç«¯é•œåƒ
â”‚
â”œâ”€â”€ frontend/              # å‰ç«¯åº”ç”¨
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ views/         # é¡µé¢
â”‚   â”‚   â”œâ”€â”€ composables/   # ç»„åˆå¼å‡½æ•°
â”‚   â”‚   â””â”€â”€ utils/         # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ mcp/                   # å°çº¢ä¹¦MCPæœåŠ¡
â”‚   â”œâ”€â”€ mcp_server.py
â”‚   â”œâ”€â”€ xiaohongshu.py
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ nginx/                 # Nginxé…ç½®
â”‚   â””â”€â”€ nginx.conf
â”‚
â”œâ”€â”€ docs/                  # æ–‡æ¡£
â”‚   â”œâ”€â”€ content_status_design.md
â”‚   â””â”€â”€ database_migration_20260213.md
â”‚
â””â”€â”€ scripts/              # è„šæœ¬å·¥å…·
    â””â”€â”€ notify_processor.py
```

---

**æ–‡æ¡£ç»´æŠ¤**: æ¯æ¬¡æ¶æ„å˜æ›´åæ›´æ–°æ­¤æ–‡æ¡£  
**æœ€åæ›´æ–°**: 2026-02-14  
**ç»´æŠ¤äºº**: å°ç‘å® ğŸ¤–  
**GitHub**: https://github.com/Jenny-Huijing/openclaw-mop

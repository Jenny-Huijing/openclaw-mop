"""
çƒ­ç‚¹è¿½è¸ªæœåŠ¡
å®ç°çƒ­ç‚¹æŠ“å–ã€åˆ†æã€æ¨é€å…¨æµç¨‹
"""
import uuid
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from difflib import SequenceMatcher

from sqlalchemy import select, desc, func
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.database import async_session_maker
from app.models import HotTopic, HotTopicTrend, HotTopicAlert
from app.services.search import search_service
from app.services.trending_platform import trending_service


class HotSpotService:
    """çƒ­ç‚¹è¿½è¸ªæœåŠ¡"""
    
    # åˆ†ç±»å…³é”®è¯é…ç½®
    CATEGORIES = {
        "finance": {
            "name": "è´¢ç»",
            "keywords": ["é™æ¯", "åŠ æ¯", "è‚¡å¸‚", "åŸºé‡‘", "ç†è´¢", "é“¶è¡Œ", "ä¿é™©", "æŠ•èµ„", "ç»æµ", "è´¢ç»"],
            "weight": 1.5
        },
        "tech": {
            "name": "ç§‘æŠ€", 
            "keywords": ["AI", "äººå·¥æ™ºèƒ½", "èŠ¯ç‰‡", "ç§‘æŠ€", "äº’è”ç½‘", "æ‰‹æœº", "ç”µåŠ¨è½¦", "æ–°èƒ½æº"],
            "weight": 1.3
        },
        "lifestyle": {
            "name": "ç”Ÿæ´»",
            "keywords": ["ç”Ÿæ´»", "ç¾é£Ÿ", "æ—…æ¸¸", "å®¶å±…", "ç©¿æ­", "æŠ¤è‚¤", "å¥èº«", "å…»ç”Ÿ"],
            "weight": 1.0
        },
        "social": {
            "name": "ç¤¾ä¼š",
            "keywords": ["ç¤¾ä¼š", "æ°‘ç”Ÿ", "æ•™è‚²", "åŒ»ç–—", "å°±ä¸š", "æˆ¿ä»·", "å…»è€", "æ”¿ç­–"],
            "weight": 1.2
        },
        "entertainment": {
            "name": "å¨±ä¹",
            "keywords": ["æ˜æ˜Ÿ", "ç»¼è‰º", "ç”µå½±", "ç”µè§†å‰§", "éŸ³ä¹", "å¨±ä¹", "å…«å¦"],
            "weight": 0.8
        }
    }
    
    # æ¨é€é˜ˆå€¼
    ALERT_THRESHOLD = {
        "new": 60,        # æ–°çƒ­ç‚¹æ¨é€é˜ˆå€¼
        "heat_rise": 50,  # çƒ­åº¦å¢é•¿è§¦å‘æ¨é€ï¼ˆç™¾åˆ†æ¯”ï¼‰
        "repeat": 50,     # é‡å¤æ¨é€éœ€è¦çš„çƒ­åº¦å¢é•¿
    }
    
    # 3å¤©å†…ä¸é‡å¤æ¨é€
    NO_REPEAT_DAYS = 3
    
    async def fetch_and_update_hotspots(self):
        """
        æŠ“å–å¹¶æ›´æ–°çƒ­ç‚¹
        ä¸»å…¥å£ï¼šå®šæ—¶ä»»åŠ¡è°ƒç”¨
        """
        print(f"[HotSpot] å¼€å§‹æŠ“å–çƒ­ç‚¹: {datetime.now()}")
        
        try:
            # 1. ä»å¤šä¸ªæºæŠ“å–çƒ­ç‚¹
            raw_hotspots = await self._fetch_from_sources()
            print(f"[HotSpot] æŠ“å–åˆ° {len(raw_hotspots)} ä¸ªåŸå§‹çƒ­ç‚¹")
            
            # 2. å¤„ç†å’Œä¿å­˜çƒ­ç‚¹
            for hotspot_data in raw_hotspots:
                await self._process_hotspot(hotspot_data)
            
            # 3. æ£€æŸ¥å¹¶æ¨é€ç‰¹åˆ«çƒ­çš„çƒ­ç‚¹
            await self._check_and_send_alerts()
            
            # 4. æ¸…ç†è¿‡æœŸçƒ­ç‚¹
            await self._clean_expired_hotspots()
            
            print(f"[HotSpot] çƒ­ç‚¹æ›´æ–°å®Œæˆ")
            
        except Exception as e:
            print(f"[HotSpot] æŠ“å–çƒ­ç‚¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    async def _fetch_from_sources(self) -> List[Dict]:
        """ä»å¤šä¸ªæºæŠ“å–çƒ­ç‚¹"""
        hotspots = []
        
        # 1. æŠ“å–å¤šå¹³å°çƒ­æœæ•°æ®
        platform_data = {}
        try:
            platform_data = await trending_service.fetch_all_trending()
            print(f"[HotSpot] æŠ“å–å¤šå¹³å°çƒ­æœ: å¾®åš{len(platform_data.get('weibo', []))}æ¡, "
                  f"ç™¾åº¦{len(platform_data.get('baidu', []))}æ¡, "
                  f"çŸ¥ä¹{len(platform_data.get('zhihu', []))}æ¡, "
                  f"å¤´æ¡{len(platform_data.get('toutiao', []))}æ¡")
        except Exception as e:
            print(f"[HotSpot] æŠ“å–å¤šå¹³å°çƒ­æœå¤±è´¥: {e}")
        
        # 2. ä½¿ç”¨æœç´¢æœåŠ¡æŠ“å–çƒ­ç‚¹
        try:
            # è´¢ç»çƒ­ç‚¹
            finance_results = await search_service.get_hotspots(count=10)
            for item in finance_results:
                title = item.get("title", "")
                
                # è®¡ç®—å¤šå¹³å°å¾®çƒ­åº¦åˆ†
                micro_heat = trending_service.calculate_micro_heat_score(title, platform_data)
                
                # ç»¼åˆçƒ­åº¦åˆ† = æœç´¢çƒ­åº¦åˆ† * 0.7 + å¾®çƒ­åº¦åˆ† * 0.3
                search_score = item.get("heat_score", 50)
                micro_score = micro_heat.get('micro_heat_score', 50)
                final_score = int(search_score * 0.7 + micro_score * 0.3)
                
                # å¦‚æœæœ‰å¹³å°åŒ¹é…ï¼Œè®°å½•å¹³å°è¯¦æƒ…
                platform_info = micro_heat.get('platform_details', {})
                matched_platforms = list(platform_info.keys())
                
                hotspots.append({
                    "title": title,
                    "summary": item.get("summary", ""),
                    "heat_score": final_score,
                    "search_score": search_score,
                    "micro_score": micro_score,
                    "matched_platforms": matched_platforms,
                    "platform_details": platform_info,
                    "source": "search",
                    "source_url": item.get("url", ""),
                    "keywords": item.get("keywords", []),
                })
                
                if matched_platforms:
                    print(f"[HotSpot] æ ‡é¢˜ '{title[:30]}...' åŒ¹é…å¹³å°: {matched_platforms}, "
                          f"å¾®çƒ­åº¦: {micro_score}, ç»¼åˆ: {final_score}")
        except Exception as e:
            print(f"[HotSpot] æŠ“å–è´¢ç»çƒ­ç‚¹å¤±è´¥: {e}")
        
        # 3. å°†å¤šå¹³å°çƒ­æœä¸­æœªåŒ¹é…çš„çƒ­é—¨è¯é¢˜ä¹ŸåŠ å…¥
        try:
            added_titles = {h['title'] for h in hotspots}
            
            for platform, items in platform_data.items():
                for item in items[:20]:  # æ¯ä¸ªå¹³å°å–å‰20
                    title = item.get('title', '')
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æ·»åŠ 
                    if title in added_titles:
                        continue
                    
                    # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦ä¸å·²æœ‰çƒ­ç‚¹ç›¸ä¼¼
                    is_similar = False
                    for existing in hotspots:
                        similarity = SequenceMatcher(None, title.lower(), existing['title'].lower()).ratio()
                        if similarity > 0.7:
                            is_similar = True
                            break
                    
                    if not is_similar and title:
                        hotspots.append({
                            "title": title,
                            "summary": f"{platform}çƒ­æœæ¦œç¬¬{item.get('rank')}å",
                            "heat_score": item.get('score', 50),
                            "search_score": 0,
                            "micro_score": item.get('score', 50),
                            "matched_platforms": [platform],
                            "platform_details": {platform: {
                                'rank': item.get('rank'),
                                'score': item.get('score'),
                                'matched_title': title,
                                'similarity': 1.0
                            }},
                            "source": platform,
                            "source_url": item.get('url', ''),
                            "keywords": [],
                        })
                        added_titles.add(title)
                        
        except Exception as e:
            print(f"[HotSpot] å¤„ç†å¤šå¹³å°çƒ­æœå¤±è´¥: {e}")
        
        return hotspots
    
    async def _process_hotspot(self, data: Dict):
        """å¤„ç†å•ä¸ªçƒ­ç‚¹æ•°æ®"""
        async with async_session_maker() as session:
            # 1. æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼çƒ­ç‚¹
            existing = await self._find_similar_topic(session, data["title"])
            
            if existing:
                # æ›´æ–°ç°æœ‰çƒ­ç‚¹
                await self._update_existing_topic(session, existing, data)
            else:
                # åˆ›å»ºæ–°çƒ­ç‚¹
                await self._create_new_topic(session, data)
            
            await session.commit()
    
    async def _find_similar_topic(self, session: AsyncSession, title: str) -> Optional[HotTopic]:
        """æŸ¥æ‰¾ç›¸ä¼¼æ ‡é¢˜çš„çƒ­ç‚¹ï¼ˆ3å¤©å†…ï¼‰"""
        three_days_ago = datetime.utcnow() - timedelta(days=self.NO_REPEAT_DAYS)
        
        result = await session.execute(
            select(HotTopic)
            .where(HotTopic.discovered_at >= three_days_ago)
            .where(HotTopic.status != "expired")
            .order_by(desc(HotTopic.discovered_at))
        )
        topics = result.scalars().all()
        
        for topic in topics:
            # ä½¿ç”¨ç›¸ä¼¼åº¦ç®—æ³•
            similarity = SequenceMatcher(None, topic.title, title).ratio()
            if similarity > 0.8:  # 80% ç›¸ä¼¼åº¦è§†ä¸ºåŒä¸€çƒ­ç‚¹
                return topic
        
        return None
    
    async def _update_existing_topic(self, session: AsyncSession, topic: HotTopic, data: Dict):
        """æ›´æ–°ç°æœ‰çƒ­ç‚¹"""
        old_heat = topic.heat_score
        new_heat = data.get("heat_score", 0)
        
        # æ›´æ–°çƒ­åº¦
        topic.heat_score = max(old_heat, new_heat)
        topic.updated_at = datetime.utcnow()
        
        # è®¡ç®—è¶‹åŠ¿
        if new_heat > old_heat * 1.3:
            topic.trend = "rising"
        elif new_heat < old_heat * 0.7:
            topic.trend = "falling"
        else:
            topic.trend = "stable"
        
        # è®°å½•è¶‹åŠ¿
        trend = HotTopicTrend(
            id=str(uuid.uuid4()),
            topic_id=topic.id,
            heat_score=new_heat,
            recorded_at=datetime.utcnow()
        )
        session.add(trend)
        
        print(f"[HotSpot] æ›´æ–°çƒ­ç‚¹: {topic.title}, çƒ­åº¦: {old_heat} -> {new_heat}")
    
    async def _create_new_topic(self, session: AsyncSession, data: Dict):
        """åˆ›å»ºæ–°çƒ­ç‚¹"""
        # åˆ†ç±»è¯†åˆ«
        category = self._classify_topic(data.get("title", "") + " " + data.get("summary", ""))
        
        topic = HotTopic(
            id=str(uuid.uuid4()),
            title=data["title"],
            summary=data.get("summary", ""),
            heat_score=data.get("heat_score", 50),
            trend="stable",
            category=category,
            source=data.get("source", "unknown"),
            source_url=data.get("source_url", ""),
            keywords=data.get("keywords", []),
            discovered_at=datetime.utcnow(),
            expires_at=datetime.utcnow() + timedelta(days=self.NO_REPEAT_DAYS),
        )
        session.add(topic)
        
        # è®°å½•åˆå§‹è¶‹åŠ¿
        trend = HotTopicTrend(
            id=str(uuid.uuid4()),
            topic_id=topic.id,
            heat_score=topic.heat_score,
            recorded_at=datetime.utcnow()
        )
        session.add(trend)
        
        print(f"[HotSpot] åˆ›å»ºæ–°çƒ­ç‚¹: {topic.title}, åˆ†ç±»: {category}, çƒ­åº¦: {topic.heat_score}")
    
    def _classify_topic(self, text: str) -> str:
        """è‡ªåŠ¨åˆ†ç±»çƒ­ç‚¹"""
        text = text.lower()
        scores = {}
        
        for key, config in self.CATEGORIES.items():
            score = 0
            for keyword in config["keywords"]:
                if keyword.lower() in text:
                    score += 1
            scores[key] = score * config["weight"]
        
        if not scores or max(scores.values()) == 0:
            return "other"
        
        best_category = max(scores, key=scores.get)
        return best_category
    
    async def _check_and_send_alerts(self):
        """æ£€æŸ¥å¹¶å‘é€æ¨é€"""
        async with async_session_maker() as session:
            # 1. æ–°çƒ­ç‚¹ï¼ˆæœªæ¨é€ä¸”çƒ­åº¦>60ï¼‰
            new_hotspots = await session.execute(
                select(HotTopic)
                .where(HotTopic.is_notified == False)
                .where(HotTopic.heat_score >= self.ALERT_THRESHOLD["new"])
                .where(HotTopic.status.in_(['active', 'DISCOVERED', 'SELECTED']))
            )
            
            for topic in new_hotspots.scalars():
                await self._send_alert(session, topic, "new")
            
            # 2. çƒ­åº¦æš´æ¶¨çš„çƒ­ç‚¹
            three_days_ago = datetime.utcnow() - timedelta(days=self.NO_REPEAT_DAYS)
            recent_alerts = await session.execute(
                select(HotTopicAlert.topic_id)
                .where(HotTopicAlert.sent_at >= three_days_ago)
                .where(HotTopicAlert.alert_type == "new")
            )
            notified_ids = {row[0] for row in recent_alerts.all()}
            
            for topic_id in notified_ids:
                # è·å–æœ€æ–°è¶‹åŠ¿
                trend_result = await session.execute(
                    select(HotTopicTrend)
                    .where(HotTopicTrend.topic_id == topic_id)
                    .order_by(desc(HotTopicTrend.recorded_at))
                    .limit(2)
                )
                trends = trend_result.scalars().all()
                
                if len(trends) >= 2:
                    latest = trends[0]
                    previous = trends[1]
                    
                    # çƒ­åº¦å¢é•¿ > 50%
                    if previous.heat_score > 0 and (latest.heat_score - previous.heat_score) / previous.heat_score > 0.5:
                        topic = await session.get(HotTopic, topic_id)
                        if topic and topic.heat_score >= self.ALERT_THRESHOLD["heat_rise"]:
                            await self._send_alert(session, topic, "heat_rise")
            
            await session.commit()
    
    async def _send_alert(self, session: AsyncSession, topic: HotTopic, alert_type: str):
        """å‘é€æ¨é€"""
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ¨é€è¿‡
        existing = await session.execute(
            select(HotTopicAlert)
            .where(HotTopicAlert.topic_id == topic.id)
            .where(HotTopicAlert.alert_type == alert_type)
            .where(HotTopicAlert.sent_at >= datetime.utcnow() - timedelta(days=1))
        )
        if existing.scalar_one_or_none():
            return  # ä»Šå¤©å·²ç»æ¨é€è¿‡
        
        # åˆ›å»ºæ¨é€è®°å½•
        alert = HotTopicAlert(
            id=str(uuid.uuid4()),
            topic_id=topic.id,
            alert_type=alert_type,
            heat_score_at_send=topic.heat_score,
            sent_at=datetime.utcnow()
        )
        session.add(alert)
        
        # æ ‡è®°çƒ­ç‚¹å·²æ¨é€
        topic.is_notified = True
        
        # å‘é€åˆ°é£ä¹¦
        await self._send_to_feishu(topic, alert_type)
        
        print(f"[HotSpot] æ¨é€çƒ­ç‚¹: {topic.title}, ç±»å‹: {alert_type}")
    
    async def _send_to_feishu(self, topic: HotTopic, alert_type: str):
        """å‘é€åˆ°é£ä¹¦"""
        try:
            from app.services.feishu import feishu_service
            
            # ç”Ÿæˆåˆ›ä½œè§’åº¦
            angle = await self._generate_angle(topic)
            
            # æ¨é€å†…å®¹
            trend_emoji = {"rising": "ğŸ”¥", "stable": "ğŸ“Š", "falling": "ğŸ“‰"}.get(topic.trend, "ğŸ“Š")
            type_text = {"new": "ğŸ†• æ–°çƒ­ç‚¹", "heat_rise": "ğŸ“ˆ çƒ­åº¦æš´æ¶¨", "daily_digest": "ğŸ“° æ¯æ—¥ç²¾é€‰"}.get(alert_type, "ğŸ”” çƒ­ç‚¹æé†’")
            
            content = f"""{type_text} - {self.CATEGORIES.get(topic.category, {}).get('name', 'å…¶ä»–')}

{trend_emoji} ã€{topic.title}ã€‘
çƒ­åº¦: {topic.heat_score}åˆ† ({topic.trend})

ğŸ’¡ åˆ›ä½œè§’åº¦:
{angle}

ğŸ“Š ç›¸å…³æ•°æ®:
- æœç´¢çƒ­åº¦: {topic.search_index}
- è®¨è®ºé‡: {topic.discuss_count}
- é˜…è¯»é‡: {topic.read_count}

ğŸ”— æ¥æº: {topic.source_url or 'æœªçŸ¥'}

â° æ¨é€æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}
"""
            
            # è¿™é‡Œéœ€è¦å®ç°é£ä¹¦æ¨é€
            # await feishu_service.send_message(content)
            print(f"[HotSpot] é£ä¹¦æ¨é€å†…å®¹:\n{content}")
            
        except Exception as e:
            print(f"[HotSpot] é£ä¹¦æ¨é€å¤±è´¥: {e}")
    
    async def _generate_angle(self, topic: HotTopic) -> str:
        """ç”Ÿæˆåˆ›ä½œè§’åº¦"""
        # æ ¹æ®åˆ†ç±»ç”Ÿæˆä¸åŒçš„è§’åº¦
        angles = {
            "finance": [
                "ä»ç†è´¢è§’åº¦åˆ†æè¿™å¯¹æ™®é€šäººçš„å½±å“",
                "åˆ†äº«3ä¸ªåº”å¯¹ç­–ç•¥ï¼Œå¸®ä½ å®ˆä½é’±è¢‹å­",
                "è§£è¯»æ”¿ç­–èƒŒåçš„æŠ•èµ„æœºä¼š"
            ],
            "tech": [
                "è¿™é¡¹æŠ€æœ¯å¦‚ä½•æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»",
                "æ™®é€šäººå¦‚ä½•æŠ“ä½è¿™æ¬¡æŠ€æœ¯çº¢åˆ©",
                "æ·±åº¦è§£æï¼šè¿™èƒŒåçš„å•†ä¸šé€»è¾‘"
            ],
            "lifestyle": [
                "äº²æµ‹åˆ†äº«ï¼šæˆ‘çš„çœŸå®ä½“éªŒ",
                "é¿å‘æŒ‡å—ï¼šè¿™äº›ç»†èŠ‚è¦æ³¨æ„",
                "æ•™ä½ 3æ‹›ï¼Œè½»æ¾ä¸Šæ‰‹"
            ],
            "social": [
                "ä»æ°‘ç”Ÿè§’åº¦è§£è¯»è¿™ä¸ªçƒ­ç‚¹",
                "è¿™å¯èƒ½æ˜¯ä½ å…³å¿ƒçš„è¯é¢˜",
                "æ”¿ç­–è§£è¯»ï¼šå¯¹æˆ‘ä»¬æœ‰ä»€ä¹ˆå½±å“"
            ]
        }
        
        import random
        category_angles = angles.get(topic.category, ["è¿™ä¸ªçƒ­ç‚¹å€¼å¾—å…³æ³¨"])
        return random.choice(category_angles)
    
    async def _clean_expired_hotspots(self):
        """æ¸…ç†è¿‡æœŸçƒ­ç‚¹"""
        async with async_session_maker() as session:
            expired = await session.execute(
                select(HotTopic)
                .where(HotTopic.expires_at <= datetime.utcnow())
                .where(HotTopic.status.in_(['active', 'DISCOVERED', 'SELECTED']))
            )
            
            for topic in expired.scalars():
                topic.status = "expired"
                print(f"[HotSpot] çƒ­ç‚¹è¿‡æœŸ: {topic.title}")
            
            await session.commit()
    
    async def get_hotspots(self, limit: int = 20, category: Optional[str] = None) -> List[Dict]:
        """è·å–çƒ­ç‚¹åˆ—è¡¨"""
        async with async_session_maker() as session:
            query = select(HotTopic).where(HotTopic.status.in_(['active', 'DISCOVERED', 'SELECTED']))
            
            if category:
                query = query.where(HotTopic.category == category)
            
            query = query.order_by(desc(HotTopic.heat_score)).limit(limit)
            
            result = await session.execute(query)
            topics = result.scalars().all()
            
            return [topic.to_dict() for topic in topics]
    
    async def get_trend(self, topic_id: str) -> List[Dict]:
        """è·å–çƒ­ç‚¹è¶‹åŠ¿"""
        async with async_session_maker() as session:
            result = await session.execute(
                select(HotTopicTrend)
                .where(HotTopicTrend.topic_id == topic_id)
                .order_by(HotTopicTrend.recorded_at)
                .limit(24)  # æœ€è¿‘24æ¡è®°å½•
            )
            trends = result.scalars().all()
            return [trend.to_dict() for trend in trends]


# å•ä¾‹
hotspot_service = HotSpotService()
